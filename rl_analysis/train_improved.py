#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏
–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –≤–µ—á–Ω—ã–º –æ–∂–∏–¥–∞–Ω–∏–µ–º –∏ —É–ª—É—á—à–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–≥—Ä–∞–¥
"""

import os
import sys
import json
import numpy as np
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback
from stable_baselines3.common.monitor import Monitor
from network_echo_env_improved import NetworkEchoEnvImproved
import matplotlib.pyplot as plt
from datetime import datetime
import time

def create_env(log_actions=True):
    """–°–æ–∑–¥–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏"""
    def make_env():
        env = NetworkEchoEnvImproved(
            config={
                'reduce_randomness': True,  # –£–º–µ–Ω—å—à–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
                'enemy_spawn_rate': 0.1,   # –£–º–µ–Ω—å—à–∞–µ–º —Å–ø–∞–≤–Ω –≤—Ä–∞–≥–æ–≤
                'resource_spawn_rate': 0.2  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
            },
            log_actions=log_actions,
            log_path="improved_training_log.jsonl",
            max_log_entries=5000
        )
        return Monitor(env)
    
    return DummyVecEnv([make_env])

def train_improved_model(total_timesteps=1000000, save_interval=50000):
    print("[DEBUG] –í—Ö–æ–¥ –≤ train_improved_model")
    print(f"[DEBUG] total_timesteps={total_timesteps}, save_interval={save_interval}")
    print("üöÄ –ó–ê–ü–£–°–ö –£–õ–£–ß–®–ï–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
    print("[DEBUG] –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    env = create_env(log_actions=True)
    print("[DEBUG] –û–∫—Ä—É–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ")
    print(f"[DEBUG] env.action_space: {env.action_space}")
    print(f"[DEBUG] env.observation_space: {env.observation_space}")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    print("[DEBUG] –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    try:
        model = PPO(
            "MlpPolicy",
            env,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=64,
            n_epochs=4,
            gamma=0.99,
            gae_lambda=0.95,
            clip_range=0.2,
            clip_range_vf=None,
            normalize_advantage=True,
            ent_coef=0.01,
            vf_coef=0.5,
            max_grad_norm=0.5,
            target_kl=None,
            tensorboard_log="./tensorboard_logs_improved/",
            verbose=0
        )
        print("[DEBUG] –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    except Exception as e:
        print(f"[DEBUG] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        raise
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–±—ç–∫–∏
    print("[DEBUG] –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–±—ç–∫–æ–≤...")
    try:
        checkpoint_callback = CheckpointCallback(
            save_freq=save_interval,
            save_path="./checkpoints_improved/",
            name_prefix="PPO_improved"
        )
        print("[DEBUG] –ö–æ–ª–±—ç–∫–∏ —Å–æ–∑–¥–∞–Ω—ã")
    except Exception as e:
        print(f"[DEBUG] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–±—ç–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        raise
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    os.makedirs("./checkpoints_improved/", exist_ok=True)
    os.makedirs("./tensorboard_logs_improved/", exist_ok=True)
    
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:")
    print(f"  üéØ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {total_timesteps:,}")
    print(f"  üíæ –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {save_interval:,}")
    print(f"  üìà Learning rate: 3e-4")
    print(f"  üéÆ Batch size: 64")
    print(f"  üîÑ N epochs: 4")
    print()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    start_time = time.time()
    print("[DEBUG] –ó–∞–ø—É—Å–∫ model.learn...")
    try:
        model.learn(
            total_timesteps=total_timesteps,
            callback=checkpoint_callback,
            progress_bar=False
        )
        print("[DEBUG] –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        final_model_path = f"improved_final_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        model.save(final_model_path)
        print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏
        interrupted_model_path = f"improved_interrupted_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        model.save(interrupted_model_path)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏: {interrupted_model_path}")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –æ—à–∏–±–∫–µ
        error_model_path = f"improved_error_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        model.save(error_model_path)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ: {error_model_path}")
    
    finally:
        env.close()
        training_time = time.time() - start_time
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time:.1f} —Å–µ–∫—É–Ω–¥")
    print("[DEBUG] –í—ã—Ö–æ–¥ –∏–∑ train_improved_model")
    return model

def analyze_improved_training():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    print("üìä –ê–ù–ê–õ–ò–ó –£–õ–£–ß–®–ï–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 40)
    
    # –ò—â–µ–º —Ñ–∞–π–ª—ã –ª–æ–≥–æ–≤
    log_files = [f for f in os.listdir('.') if f.startswith('improved_log_') and f.endswith('.jsonl')]
    
    if not log_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –ª–æ–≥–æ–≤ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
        return
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª
    latest_log = max(log_files)
    print(f"üìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {latest_log}")
    
    # –ß–∏—Ç–∞–µ–º –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏
    episodes = []
    actions = []
    rewards = []
    
    with open(latest_log, 'r') as f:
        for line in f:
            try:
                data = json.loads(line.strip())
                if data.get('type') == 'action':
                    actions.append(data['chosen_action']['action'])
                    rewards.append(data.get('improved_reward', 0))
                elif data.get('type') == 'episode_end':
                    episodes.append({
                        'episode': data['episode'],
                        'total_steps': data['total_steps'],
                        'total_reward': data['total_reward'],
                        'final_score': data['final_score'],
                        'win': data['win']
                    })
            except json.JSONDecodeError:
                continue
    
    if not episodes:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —ç–ø–∏–∑–æ–¥–æ–≤")
        return
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è:")
    print(f"  üéÆ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: {len(episodes)}")
    print(f"  ‚ö° –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π: {len(actions)}")
    print(f"  üéØ –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {np.mean(rewards):.3f}")
    print(f"  üìä –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞: {np.mean([ep['total_steps'] for ep in episodes]):.1f}")
    print(f"  üèÜ –ü–æ–±–µ–¥: {sum(1 for ep in episodes if ep['win'])}")
    print()
    
    # –ê–Ω–∞–ª–∏–∑ –¥–µ–π—Å—Ç–≤–∏–π
    action_counts = {}
    for action in actions:
        action_counts[action] = action_counts.get(action, 0) + 1
    
    print("üéÆ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π:")
    total_actions = len(actions)
    for action, count in sorted(action_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_actions) * 100
        print(f"  {action}: {count} ({percentage:.1f}%)")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    create_improved_visualization(episodes, actions, rewards)

def create_improved_visualization(episodes, actions, rewards):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # –ì—Ä–∞—Ñ–∏–∫ –Ω–∞–≥—Ä–∞–¥ –ø–æ —ç–ø–∏–∑–æ–¥–∞–º
    episode_rewards = [ep['total_reward'] for ep in episodes]
    episode_numbers = [ep['episode'] for ep in episodes]
    
    ax1.plot(episode_numbers, episode_rewards, 'b-o', linewidth=2, markersize=6)
    ax1.set_title('–ù–∞–≥—Ä–∞–¥—ã –ø–æ —ç–ø–∏–∑–æ–¥–∞–º (—É–ª—É—á—à–µ–Ω–Ω—ã–µ)', fontsize=14, fontweight='bold')
    ax1.set_xlabel('–≠–ø–∏–∑–æ–¥')
    ax1.set_ylabel('–û–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞')
    ax1.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ –¥–ª–∏–Ω—ã —ç–ø–∏–∑–æ–¥–æ–≤
    episode_lengths = [ep['total_steps'] for ep in episodes]
    ax2.plot(episode_numbers, episode_lengths, 'g-o', linewidth=2, markersize=6)
    ax2.set_title('–î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–æ–≤', fontsize=14, fontweight='bold')
    ax2.set_xlabel('–≠–ø–∏–∑–æ–¥')
    ax2.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤')
    ax2.grid(True, alpha=0.3)
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π
    action_counts = {}
    for action in actions:
        action_counts[action] = action_counts.get(action, 0) + 1
    
    action_names = list(action_counts.keys())
    action_values = list(action_counts.values())
    colors = plt.cm.Set3(np.linspace(0, 1, len(action_names)))
    
    ax3.pie(action_values, labels=action_names, autopct='%1.1f%%', 
             colors=colors, startangle=90)
    ax3.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π', fontsize=14, fontweight='bold')
    
    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –Ω–∞–≥—Ä–∞–¥
    ax4.hist(rewards, bins=50, alpha=0.7, color='orange', edgecolor='black')
    ax4.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥', fontsize=14, fontweight='bold')
    ax4.set_xlabel('–ù–∞–≥—Ä–∞–¥–∞')
    ax4.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('improved_training_analysis.png', dpi=300, bbox_inches='tight')
    print("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: improved_training_analysis.png")
    plt.show()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("ü§ñ –£–õ–£–ß–®–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 50)
    print("1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
    print("2. –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    print("3. –í—ã—Ö–æ–¥")
    
    try:
        choice_input = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (1-3): ").strip()
        if not choice_input:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥")
            return
        choice = int(choice_input)
        
        if choice == 1:
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
            total_steps_input = input("–í–≤–µ–¥–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1,000,000): ").strip()
            total_steps = int(total_steps_input) if total_steps_input else 1000000
            
            save_interval_input = input("–í–≤–µ–¥–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 50,000): ").strip()
            save_interval = int(save_interval_input) if save_interval_input else 50000
            
            print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {total_steps:,} —à–∞–≥–æ–≤...")
            model = train_improved_model(total_steps, save_interval)
            
        elif choice == 2:
            analyze_improved_training()
            
        elif choice == 3:
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
            
    except ValueError:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥")
    except KeyboardInterrupt:
        print("\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")

if __name__ == "__main__":
    main() 