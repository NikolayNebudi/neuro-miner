#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –ø—Ä–∏—á–∏–Ω –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –≤ RL-–æ–±—É—á–µ–Ω–∏–∏
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def analyze_instability(csv_file='analysis_log.csv'):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏—á–∏–Ω—ã –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv(csv_file, header=None, names=[
        'episode_id', 'stage', 'result', 'reward', 'steps', 'trace',
        'program_counts', 'avg_levels', 'enemies_killed', 'total_dp', 'total_cpu'
    ])
    
    print("üîç –ê–Ω–∞–ª–∏–∑ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("=" * 60)
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
    print("üö® –í–´–Ø–í–õ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
    
    # 1. –ü—Ä–æ–±–ª–µ–º–∞ —Å —ç—Ç–∞–ø–∞–º–∏
    stage_counts = df['stage'].value_counts()
    print(f"\n1Ô∏è‚É£  –ù–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —ç—Ç–∞–ø–∞–º:")
    for stage, count in stage_counts.items():
        percentage = count / len(df) * 100
        print(f"   –≠—Ç–∞–ø {stage}: {count} —ç–ø–∏–∑–æ–¥–æ–≤ ({percentage:.1f}%)")
    
    # 2. –ü—Ä–æ–±–ª–µ–º–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    result_counts = df['result'].value_counts()
    print(f"\n2Ô∏è‚É£  –ö—Ä–∞–π–Ω–µ –Ω–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ–±–µ–¥:")
    for result, count in result_counts.items():
        percentage = count / len(df) * 100
        print(f"   {result}: {count} ({percentage:.1f}%)")
    
    # 3. –ê–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞–≥—Ä–∞–¥
    print(f"\n3Ô∏è‚É£  –í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞–≥—Ä–∞–¥:")
    for stage in sorted(df['stage'].unique()):
        stage_data = df[df['stage'] == stage]
        rewards = stage_data['reward'].values
        print(f"   –≠—Ç–∞–ø {stage}:")
        print(f"     –°—Ä–µ–¥–Ω–µ–µ: {rewards.mean():.2f}")
        print(f"     –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {rewards.std():.2f}")
        print(f"     –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {rewards.std() / abs(rewards.mean()):.2f}")
    
    # 4. –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    print(f"\n4Ô∏è‚É£  –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:")
    numeric_cols = ['reward', 'steps', 'total_dp']
    numeric_data = df[numeric_cols].copy()
    
    # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
    numeric_data = numeric_data.dropna()
    
    if len(numeric_data) > 0:
        corr_matrix = numeric_data.corr()
        print("   –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:")
        for i, col1 in enumerate(numeric_cols):
            for j, col2 in enumerate(numeric_cols):
                if i < j:
                    corr = corr_matrix.loc[col1, col2]
                    print(f"     {col1} ‚Üî {col2}: {corr:.3f}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                    if abs(corr) > 0.9:
                        print(f"       ‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è!")
                    elif abs(corr) < 0.1:
                        print(f"       ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è!")
    
    # 5. –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    print(f"\n5Ô∏è‚É£  –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:")
    recent_results = df.tail(20)['result'].values
    print(f"   –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    
    # –ü–æ–¥—Å—á–µ—Ç —Å–µ—Ä–∏–π
    win_streaks = []
    loss_streaks = []
    current_streak = 1
    current_result = recent_results[0]
    
    for i in range(1, len(recent_results)):
        if recent_results[i] == current_result:
            current_streak += 1
        else:
            if current_result == 'win':
                win_streaks.append(current_streak)
            else:
                loss_streaks.append(current_streak)
            current_streak = 1
            current_result = recent_results[i]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ—Ä–∏—é
    if current_result == 'win':
        win_streaks.append(current_streak)
    else:
        loss_streaks.append(current_streak)
    
    print(f"   –°–µ—Ä–∏–∏ –ø–æ–±–µ–¥: {win_streaks}")
    print(f"   –°–µ—Ä–∏–∏ –ø–æ—Ä–∞–∂–µ–Ω–∏–π: {loss_streaks}")
    
    if len(loss_streaks) > 0 and max(loss_streaks) > 5:
        print(f"   ‚ö†Ô∏è  –î–ª–∏–Ω–Ω—ã–µ —Å–µ—Ä–∏–∏ –ø–æ—Ä–∞–∂–µ–Ω–∏–π ({max(loss_streaks)} –ø–æ–¥—Ä—è–¥)")
    
    # 6. –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
    print(f"\n6Ô∏è‚É£  –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    
    for stage in sorted(df['stage'].unique()):
        stage_data = df[df['stage'] == stage]
        if len(stage_data) > 10:
            rewards = stage_data['reward'].values
            q25, q75 = np.percentile(rewards, [25, 75])
            iqr = q75 - q25
            lower_bound = q25 - 1.5 * iqr
            upper_bound = q75 + 1.5 * iqr
            
            outliers = stage_data[(stage_data['reward'] < lower_bound) | (stage_data['reward'] > upper_bound)]
            if len(outliers) > 0:
                print(f"   –≠—Ç–∞–ø {stage}: {len(outliers)} –≤—ã–±—Ä–æ—Å–æ–≤ –∏–∑ {len(stage_data)} —ç–ø–∏–∑–æ–¥–æ–≤")
                for _, row in outliers.iterrows():
                    print(f"     –ù–∞–≥—Ä–∞–¥–∞: {row['reward']:.2f}, —à–∞–≥–∏: {row['steps']}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {row['result']}")

def suggest_solutions():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º"""
    
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:")
    
    print(f"\n1Ô∏è‚É£  –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —ç—Ç–∞–ø–∞–º")
    print(f"   –†–µ—à–µ–Ω–∏—è:")
    print(f"   - –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ")
    print(f"   - –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —ç—Ç–∞–ø—ã —Å–ª–æ–∂–Ω–æ—Å—Ç–∏")
    print(f"   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å curriculum learning —Å –ø–ª–∞–≤–Ω—ã–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞–º–∏")
    
    print(f"\n2Ô∏è‚É£  –ü—Ä–æ–±–ª–µ–º–∞: –ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ–±–µ–¥ (2%)")
    print(f"   –†–µ—à–µ–Ω–∏—è:")
    print(f"   - –£–ø—Ä–æ—Å—Ç–∏—Ç—å —É—Å–ª–æ–≤–∏—è –ø–æ–±–µ–¥—ã –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö")
    print(f"   - –£–≤–µ–ª–∏—á–∏—Ç—å –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–±–æ–ª—å—à–µ —ç–ø–∏–∑–æ–¥–æ–≤)")
    print(f"   - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å shaping rewards –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π")
    print(f"   - –î–æ–±–∞–≤–∏—Ç—å exploration bonus –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
    
    print(f"\n3Ô∏è‚É£  –ü—Ä–æ–±–ª–µ–º–∞: –í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print(f"   –†–µ—à–µ–Ω–∏—è:")
    print(f"   - –£–º–µ–Ω—å—à–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏")
    print(f"   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
    print(f"   - –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –≤ –ø–æ–ª–∏—Ç–∏–∫—É")
    print(f"   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ensemble –º–µ—Ç–æ–¥—ã")
    
    print(f"\n4Ô∏è‚É£  –ü—Ä–æ–±–ª–µ–º–∞: –î–ª–∏–Ω–Ω—ã–µ —Å–µ—Ä–∏–∏ –ø–æ—Ä–∞–∂–µ–Ω–∏–π")
    print(f"   –†–µ—à–µ–Ω–∏—è:")
    print(f"   - –î–æ–±–∞–≤–∏—Ç—å early stopping –ø—Ä–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Å–µ—Ä–∏—è—Ö")
    print(f"   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å adaptive learning rate")
    print(f"   - –î–æ–±–∞–≤–∏—Ç—å exploration strategies (epsilon-greedy)")
    print(f"   - –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å experience replay —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏")
    
    print(f"\n5Ô∏è‚É£  –ü—Ä–æ–±–ª–µ–º–∞: –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –Ω–∞–≥—Ä–∞–¥–∞-—à–∞–≥–∏")
    print(f"   –†–µ—à–µ–Ω–∏—è:")
    print(f"   - –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞–≥—Ä–∞–¥—ã –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—Ä–µ—Å—É—Ä—Å—ã, –≤—Ä–µ–º—è, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)")
    print(f"   - –î–æ–±–∞–≤–∏—Ç—å sparse rewards –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π")
    print(f"   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å multi-objective optimization")
    
    print(f"\nüîß –ö–û–ù–ö–†–ï–¢–ù–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø –í –ö–û–î–ï:")
    print(f"   1. –í train.py:")
    print(f"      - –£–≤–µ–ª–∏—á–∏—Ç—å EPISODES_PER_STAGE –¥–æ 500000")
    print(f"      - –î–æ–±–∞–≤–∏—Ç—å early stopping")
    print(f"      - –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å adaptive learning rate")
    
    print(f"   2. –í game_engine.js:")
    print(f"      - –£–º–µ–Ω—å—à–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å —Å–ø–∞–≤–Ω–∞ –≤—Ä–∞–≥–æ–≤")
    print(f"      - –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã")
    print(f"      - –£–ø—Ä–æ—Å—Ç–∏—Ç—å —É—Å–ª–æ–≤–∏—è –ø–æ–±–µ–¥—ã –Ω–∞ —ç—Ç–∞–ø–µ 0")
    
    print(f"   3. –í network_echo_env.py:")
    print(f"      - –£–ª—É—á—à–∏—Ç—å shaping rewards")
    print(f"      - –î–æ–±–∞–≤–∏—Ç—å exploration bonus")
    print(f"      - –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å curriculum learning")

def create_improvement_plan():
    """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π"""
    
    print(f"\nüìã –ü–õ–ê–ù –£–õ–£–ß–®–ï–ù–ò–ô:")
    
    print(f"\nüéØ –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (1-2 –¥–Ω—è):")
    print(f"   1. –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–æ 500k –Ω–∞ —ç—Ç–∞–ø")
    print(f"   2. –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã –∑–∞ —Ä–µ—Å—É—Ä—Å—ã")
    print(f"   3. –£–ø—Ä–æ—Å—Ç–∏—Ç—å —É—Å–ª–æ–≤–∏—è –ø–æ–±–µ–¥—ã –Ω–∞ —ç—Ç–∞–ø–µ 0")
    print(f"   4. –£–º–µ–Ω—å—à–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏")
    
    print(f"\nüéØ –°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (1 –Ω–µ–¥–µ–ª—è):")
    print(f"   1. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å curriculum learning")
    print(f"   2. –î–æ–±–∞–≤–∏—Ç—å exploration strategies")
    print(f"   3. –£–ª—É—á—à–∏—Ç—å shaping rewards")
    print(f"   4. –î–æ–±–∞–≤–∏—Ç—å early stopping")
    
    print(f"\nüéØ –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (2-4 –Ω–µ–¥–µ–ª–∏):")
    print(f"   1. Multi-objective optimization")
    print(f"   2. Ensemble methods")
    print(f"   3. Advanced exploration (PPO with curiosity)")
    print(f"   4. Hyperparameter optimization")

if __name__ == "__main__":
    try:
        analyze_instability()
        suggest_solutions()
        create_improvement_plan()
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìä –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã:")
        print(f"   - –°–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —ç—Ç–∞–ø–µ 0")
        print(f"   - –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
        print(f"   - –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        print(f"   - –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–ª—É—á—à–∏—Ç—å reward shaping")
        
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª analysis_log.csv –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}") 