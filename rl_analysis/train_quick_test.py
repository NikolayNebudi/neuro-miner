#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
"""

import os
import csv
import uuid
import gymnasium as gym
from stable_baselines3 import PPO
from stable_baselines3.common.env_checker import check_env
from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback
from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor
from network_echo_env_improved import NetworkEchoEnvImproved
import numpy as np
from datetime import datetime

# –£–ü–†–û–©–ï–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø
EPISODES_PER_STAGE = 1000  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
LEARNING_RATE = 1e-4
N_STEPS = 1024
BATCH_SIZE = 64
N_EPOCHS = 4
ENT_COEF = 0.01

LOG_PATH = os.path.join(os.path.dirname(__file__), 'quick_test_log.csv')
MODEL_PATH = os.path.join(os.path.dirname(__file__), 'ppo_quick_test.zip')

class SimpleCallback(BaseCallback):
    """–ü—Ä–æ—Å—Ç–æ–π callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self, verbose=1):
        super().__init__(verbose)
        self.episode_count = 0
        
    def _on_step(self) -> bool:
        self.episode_count += 1
        if self.episode_count % 100 == 0:
            if self.verbose > 0:
                print(f"–®–∞–≥ {self.episode_count}")
        return True

def log_episode_quick(session_id, stage, win, reason, score, steps, trace, final_stats=None):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä"""
    file_exists = os.path.isfile(LOG_PATH)
    with open(LOG_PATH, 'a', newline='') as csvfile:
        writer = csv.writer(csvfile)
        if not file_exists:
            writer.writerow([
                'session_id', 'stage', 'win', 'reason_for_end', 'final_score', 'total_steps', 'final_trace_level',
                'program_counts', 'avg_levels', 'enemies_killed', 'total_dp', 'total_cpu', 'timestamp'
            ])
        row = [session_id, stage, win, reason, score, steps, trace]
        if final_stats:
            row.append(str(final_stats.get('program_counts', {})))
            row.append(str(final_stats.get('avg_levels', {})))
            row.append(final_stats.get('enemies_killed', 0))
            row.append(final_stats.get('total_dp', 0))
            row.append(final_stats.get('total_cpu', 0))
        else:
            row += ['', '', '', '', '']
        row.append(datetime.now().isoformat())
        writer.writerow(row)

def create_test_env(stage=0, mode='full'):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ"""
    config = {
        'mode': mode,
        'stage': stage,
        'reduce_randomness': True,
        'improved_rewards': True,
        'curriculum_learning': True
    }
    
    env = NetworkEchoEnvImproved(config=config)
    return env

def train_stage_quick(stage_name, stage_config, model=None):
    """–û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —Å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    
    print(f"\nüéØ –≠—Ç–∞–ø: {stage_name}")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
    env = create_test_env(stage_config['stage'], stage_config['mode'])
    env = DummyVecEnv([lambda: env])
    env = VecMonitor(env, LOG_PATH)
    
    # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    if model is None:
        model = PPO(
            "MlpPolicy",
            env,
            learning_rate=LEARNING_RATE,
            n_steps=N_STEPS,
            batch_size=BATCH_SIZE,
            n_epochs=N_EPOCHS,
            gamma=0.99,
            gae_lambda=0.95,
            clip_range=0.2,
            clip_range_vf=None,
            normalize_advantage=True,
            ent_coef=ENT_COEF,
            vf_coef=0.5,
            max_grad_norm=0.5,
            use_sde=False,
            target_kl=None,
            tensorboard_log="./tensorboard_logs/",
            verbose=1
        )
    else:
        model.set_env(env)
    
    # –ü—Ä–æ—Å—Ç—ã–µ callbacks
    callbacks = [
        SimpleCallback(verbose=1),
        CheckpointCallback(
            save_freq=max(1000, EPISODES_PER_STAGE // 10),
            save_path=f"./checkpoints/quick_stage_{stage_config['stage']}/",
            name_prefix="ppo_model"
        )
    ]
    
    # –û–±—É—á–µ–Ω–∏–µ
    try:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–∞–ø–∞ {stage_name}...")
        print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: episodes={EPISODES_PER_STAGE}, lr={LEARNING_RATE}, batch_size={BATCH_SIZE}")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model.learn(
            total_timesteps=EPISODES_PER_STAGE * 100,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            callback=callbacks,
            progress_bar=False
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        model_path = f"ppo_quick_stage_{stage_config['stage']}.zip"
        model.save(model_path)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        
        return model
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —ç—Ç–∞–ø–∞ {stage_name}: {e}")
        return model
    finally:
        env.close()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ RL-–æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    print("=" * 60)
    print(f"–¢–µ—Å—Ç–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"  - –≠–ø–∏–∑–æ–¥–æ–≤ –Ω–∞ —ç—Ç–∞–ø: {EPISODES_PER_STAGE:,}")
    print(f"  - Learning rate: {LEARNING_RATE}")
    print(f"  - Batch size: {BATCH_SIZE}")
    print(f"  - N steps: {N_STEPS}")
    print(f"  - Entropy coefficient: {ENT_COEF}")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
    os.makedirs("./checkpoints", exist_ok=True)
    
    # –≠—Ç–∞–ø—ã –æ–±—É—á–µ–Ω–∏—è —Å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    stages = [
        {
            "name": "–≠–∫–æ–Ω–æ–º–∏–∫–∞ (—Ç–µ—Å—Ç)",
            "stage": 0,
            "mode": "economy_tutorial",
            "episodes": EPISODES_PER_STAGE
        },
        {
            "name": "–û–±–æ—Ä–æ–Ω–∞ (—Ç–µ—Å—Ç)",
            "stage": 1,
            "mode": "defense_tutorial", 
            "episodes": EPISODES_PER_STAGE
        },
        {
            "name": "–ü–æ–ª–Ω–∞—è –∏–≥—Ä–∞ (—Ç–µ—Å—Ç)",
            "stage": 2,
            "mode": "full",
            "episodes": EPISODES_PER_STAGE
        }
    ]
    
    model = None
    
    for stage_idx, stage_config in enumerate(stages):
        print(f"\nüéØ –≠—Ç–∞–ø {stage_idx + 1}/{len(stages)}: {stage_config['name']}")
        
        # –û–±—É—á–∞–µ–º —ç—Ç–∞–ø
        model = train_stage_quick(stage_config['name'], stage_config, model)
        
        if model is None:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ {stage_idx + 1}, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ")
            break
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    if model is not None:
        model.save(MODEL_PATH)
        print(f"\n‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_PATH}")
    
    print(f"\nüéâ –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {LOG_PATH}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {MODEL_PATH}")

if __name__ == "__main__":
    main() 